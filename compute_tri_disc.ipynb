{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: Compute triangular discriminator to classify unfolding performance. See Table 1: https://arxiv.org/pdf/1911.09107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 14:54:29.969846: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-02 14:54:29.969880: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-02 14:54:29.971641: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-02 14:54:29.980795: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-02 14:54:31.446551: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horovod not found, will continue with single only GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/a/aelabd/omnifold_hvod/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import copy\n",
    "from tabulate import tabulate\n",
    "\n",
    "import energyflow as ef # for data\n",
    "import omnifold\n",
    "\n",
    "# Local imports for plotting (source: https://github.com/ericmetodiev/OmniFold/blob/master/modplot.py)\n",
    "import modplot\n",
    "from hist_utils import obs, calc_obs, hist_style, gen_style, truth_style, omnifold_style, multifold_style, ibu_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_DATA = 1.6e6\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (4,4)\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "# IBU hyperparameters\n",
    "N_ITER_IBU = 3\n",
    "\n",
    "# OmniFold hyperparameters\n",
    "N_ITER_OF = 5\n",
    "LR_OF = 5e-5\n",
    "LR_PATIENCE_OF = 10\n",
    "BATCH_SIZE_OF = 1000\n",
    "EPOCHS_OF = 100\n",
    "NUM_HEAD_OF = 8\n",
    "NUM_TRANSFORMER_OF = 4\n",
    "PROJECTION_DIM_OF = 97\n",
    "\n",
    "# Multifold hyperparameters\n",
    "LAYER_SIZES = [64, 128, 64]\n",
    "N_ITER_MF = 3\n",
    "BATCH_SIZE_MF = 500\n",
    "EPOCHS_MF = 2\n",
    "\n",
    "# Other globals \n",
    "N_DATA = int(1.6e6)\n",
    "OBS_MULTIFOLD = ['Mass', 'Mult', 'Width',  'SDMass', 'Tau21', 'zg']\n",
    "N_JOBS = 16\n",
    "\n",
    "np.random.seed(0)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "l10data = int(np.log10(N_DATA))\n",
    "print(f\"N_DATA = {N_DATA/(10**(l10data))}e{int(l10data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pythia as the Monte Carlo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Creating weights ...\n",
      "INFO: Creating pass reco flag ...\n",
      "INFO: Creating pass gen flag ...\n"
     ]
    }
   ],
   "source": [
    "data_mc_dict = ef.zjets_delphes.load('Pythia26', exclude_keys='particles', num_data=N_DATA, pad=True, source='zenodo', which='all')\n",
    "obs_mc_gen = {k.replace(\"gen_\", \"\"): data_mc_dict[k] for k in data_mc_dict.keys() if (('gen_' in k) and ('particle' not in k))}\n",
    "obs_mc_sim = {k.replace(\"sim_\", \"\"): data_mc_dict[k] for k in data_mc_dict.keys() if (('sim_' in k) and ('particle' not in k))}\n",
    "\n",
    "obs_mc_gen['Mass'] = obs_mc_gen['jets'][:,3]\n",
    "obs_mc_gen.pop('jets')\n",
    "obs_mc_gen['Mult'] = obs_mc_gen.pop('mults')\n",
    "obs_mc_gen['Width'] = obs_mc_gen.pop('widths')\n",
    "obs_mc_gen['Tau21'] = obs_mc_gen.pop('tau2s')\n",
    "obs_mc_gen['zg'] = obs_mc_gen.pop('zgs')\n",
    "obs_mc_gen['SDMass'] = obs_mc_gen.pop('sdms')\n",
    "obs_mc_gen = np.concatenate([obs_mc_gen[k].reshape((N_DATA,1)) for k in OBS_MULTIFOLD], axis=1)\n",
    "\n",
    "\n",
    "obs_mc_sim['Mass'] = obs_mc_sim['jets'][:,3]\n",
    "obs_mc_sim.pop('jets')\n",
    "obs_mc_sim['Mult'] = obs_mc_sim.pop('mults')\n",
    "obs_mc_sim['Width'] = obs_mc_sim.pop('widths')\n",
    "obs_mc_sim['Tau21'] = obs_mc_sim.pop('tau2s')\n",
    "obs_mc_sim['zg'] = obs_mc_sim.pop('zgs')\n",
    "obs_mc_sim['SDMass'] = obs_mc_sim.pop('sdms')\n",
    "obs_mc_sim = np.concatenate([obs_mc_sim[k].reshape((N_DATA,1)) for k in OBS_MULTIFOLD], axis=1)\n",
    "obs_mc = omnifold.DataLoader(reco=copy.deepcopy(obs_mc_sim), gen=copy.deepcopy(obs_mc_gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hedwig as the \"true\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Creating weights ...\n",
      "INFO: Creating pass reco flag ...\n",
      "INFO: Creating pass gen flag ...\n"
     ]
    }
   ],
   "source": [
    "data_nature_dict = ef.zjets_delphes.load('Herwig', exclude_keys='particles', num_data=N_DATA, pad=True, source='zenodo', which='all')\n",
    "obs_nature_gen = {k.replace(\"gen_\", \"\"): data_nature_dict[k] for k in data_nature_dict.keys() if (('gen_' in k) and ('particle' not in k))}\n",
    "obs_nature_sim = {k.replace(\"sim_\", \"\"): data_nature_dict[k] for k in data_nature_dict.keys() if (('sim_' in k) and ('particle' not in k))}\n",
    "\n",
    "obs_nature_gen['Mass'] = obs_nature_gen['jets'][:,3]\n",
    "obs_nature_gen.pop('jets')\n",
    "obs_nature_gen['Mult'] = obs_nature_gen.pop('mults')\n",
    "obs_nature_gen['Width'] = obs_nature_gen.pop('widths')\n",
    "obs_nature_gen['Tau21'] = obs_nature_gen.pop('tau2s')\n",
    "obs_nature_gen['zg'] = obs_nature_gen.pop('zgs')\n",
    "obs_nature_gen['SDMass'] = obs_nature_gen.pop('sdms')\n",
    "obs_nature_gen = np.concatenate([obs_nature_gen[k].reshape((N_DATA,1)) for k in OBS_MULTIFOLD], axis=1)\n",
    "\n",
    "obs_nature_sim['Mass'] = obs_nature_sim['jets'][:,3]\n",
    "obs_nature_sim.pop('jets')\n",
    "obs_nature_sim['Mult'] = obs_nature_sim.pop('mults')\n",
    "obs_nature_sim['Width'] = obs_nature_sim.pop('widths')\n",
    "obs_nature_sim['Tau21'] = obs_nature_sim.pop('tau2s')\n",
    "obs_nature_sim['zg'] = obs_nature_sim.pop('zgs')\n",
    "obs_nature_sim['SDMass'] = obs_nature_sim.pop('sdms')\n",
    "obs_nature_sim = np.concatenate([obs_nature_sim[k].reshape((N_DATA,1)) for k in OBS_MULTIFOLD], axis=1)\n",
    "\n",
    "obs_nature = omnifold.DataLoader(reco=copy.deepcopy(obs_nature_sim), gen=copy.deepcopy(obs_nature_gen))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute IBU rq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Calculating IBU...\n",
      "\n",
      "Done with Mass\n",
      "Done with Mult\n",
      "Done with Width\n",
      "Done with Tau21\n",
      "Done with zg\n",
      "Done with SDMass\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nCalculating IBU...\\n\")\n",
    "calc_obs(obs_dict=obs, data_synth=data_mc_dict, data_real=data_nature_dict, itnum=N_ITER_IBU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Compute the \"true\" probability distribution, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n",
      "(80,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "q_dict = {}\n",
    "for k in OBS_MULTIFOLD:\n",
    "    q_dict[k] = obs[k][\"truth_hist\"].copy()/sum(obs[k][\"truth_hist\"])\n",
    "    print(q_dict[k].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Compute the IBU probability distribution, $p_{\\text{IBU}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n",
      "(80,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "p_ibu_dict = {}\n",
    "for k in OBS_MULTIFOLD:\n",
    "    p_ibu_dict[k] = obs[k][\"ibu_phis\"][-1].copy()/sum(obs[k][\"ibu_phis\"][-1])\n",
    "    print(p_ibu_dict[k].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Compute the MultiFold probability distribution, $p_{\\text{MF}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n",
      "(80,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "# weights_mf = np.load(\"hist_weights/\"+ f\"MultiFold_niter{N_ITER_MF}_bs{BATCH_SIZE_MF}_ep{EPOCHS_MF}_layers{LAYER_SIZES[0]}_{LAYER_SIZES[1]}_{LAYER_SIZES[2]}\" + \"_final_weights.npy\")\n",
    "weights_mf = np.load(f\"hist_weights_old/MultiFold_N1.6e6_niter{N_ITER_MF}_bs{BATCH_SIZE_MF}_ep{EPOCHS_MF}_weights_push.npy\")\n",
    "\n",
    "p_mf_dict = {}\n",
    "for k in OBS_MULTIFOLD:\n",
    "    mf_histgen, mf_histgen_unc = modplot.calc_hist(obs[k]['genobs'], weights=weights_mf, \n",
    "                                                    bins=obs[k]['bins_mc'], density=True)[:2]\n",
    "    p_mf_dict[k] = mf_histgen.copy()/sum(mf_histgen)\n",
    "    print(p_mf_dict[k].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Compute the OmniFold probability distribution, $p_{\\text{OF}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n",
      "(80,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "# weights_of = np.load(\"hist_weights/\"+ f\"OmniFold_niter{N_ITER_OF}_lr{LR_OF}_lrp{LR_PATIENCE_OF}_bs{BATCH_SIZE_OF}_ep{EPOCHS_OF}_nhead{NUM_HEAD_OF}_ntl{NUM_TRANSFORMER_OF}_pdim{PROJECTION_DIM_OF}\" + \"_final_weights.npy\")\n",
    "weights_of = np.load(f\"hist_weights_old/OmniFold_N1.6e6_niter{N_ITER_OF}_bs{BATCH_SIZE_OF}_ep{EPOCHS_OF}_final_weights.npy\")\n",
    "\n",
    "p_of_dict = {}\n",
    "for k in OBS_MULTIFOLD:\n",
    "    of_histgen, of_histgen_unc = modplot.calc_hist(obs[k]['genobs'], weights=weights_of, \n",
    "                                                    bins=obs[k]['bins_mc'], density=True)[:2]\n",
    "    p_of_dict[k] = of_histgen.copy()/sum(of_histgen)\n",
    "    print(p_of_dict[k].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Compute triangular discriminant table\n",
    "\n",
    "$ \\Delta(p, q) = \\frac{1}{2} \\int \\frac{(p(\\lambda)-q(\\lambda))^2}{p(\\lambda)+q(\\lambda)} d\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_delta(p, q):\n",
    "    numerator = (p-q)**2\n",
    "    denominator = p+q+1e-50\n",
    "    delta = 1e3*(1/2)*np.sum(numerator/denominator)\n",
    "    return delta\n",
    "\n",
    "delta_dict = {\"IBU\": {}, \"MultiFold\": {}, \"OmniFold\": {}}\n",
    "for k in OBS_MULTIFOLD:\n",
    "    delta_dict['IBU'][k] = compute_delta(p_ibu_dict[k], q_dict[k])\n",
    "    delta_dict['MultiFold'][k] = compute_delta(p_mf_dict[k], q_dict[k])\n",
    "    delta_dict['OmniFold'][k] = compute_delta(p_of_dict[k], q_dict[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+-----------+----------+---------+----------+\n",
      "| Method    |        m |        M |         w |   SDMass |     t21 |       zg |\n",
      "+===========+==========+==========+===========+==========+=========+==========+\n",
      "| OmniFold  |  2.80544 | 0.445316 | 0.760862  | 1.25528  | 4.59479 | 0.90784  |\n",
      "+-----------+----------+----------+-----------+----------+---------+----------+\n",
      "| MultiFold | 11.3429  | 4.78266  | 2.45608   | 3.89037  | 2.45785 | 0.810493 |\n",
      "+-----------+----------+----------+-----------+----------+---------+----------+\n",
      "| IBU       |  7.19566 | 1.11647  | 0.0713979 | 0.439882 | 3.53143 | 0.976731 |\n",
      "+-----------+----------+----------+-----------+----------+---------+----------+\n"
     ]
    }
   ],
   "source": [
    "headers = [\"Method\", \"m\", \"M\", \"w\", \"SDMass\", \"t21\", \"zg\"]\n",
    "tri_disc_data = [\n",
    "    [\"OmniFold\"],\n",
    "    [\"MultiFold\"],\n",
    "    [\"IBU\"],\n",
    "]\n",
    "tri_disc_data[0].extend(delta_dict[\"OmniFold\"].values())\n",
    "tri_disc_data[1].extend(delta_dict[\"MultiFold\"].values())\n",
    "tri_disc_data[2].extend(delta_dict[\"IBU\"].values())\n",
    "\n",
    "\n",
    "print(tabulate(tri_disc_data, headers=headers, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnifold_hvod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
